#!/usr/bin/env python
"""
05_regression_review_score.py

Script para modelar a nota de review (review_score) como vari√°vel cont√≠nua,
usando Regress√£o Linear e Ridge.

Fluxo:
- L√™ data/processed/olist_model_dataset.csv
- Usa review_score como target cont√≠nuo
- Usa as mesmas features num√©ricas/categ√≥ricas da parte supervisionada
- Divide em treino/teste
- Treina:
    - Regress√£o Linear
    - Regress√£o Ridge
- Avalia com:
    - RMSE
    - R¬≤
- Salva:
    - results/regression/regression_results.json
    - results/regression/parity_plot_linear.png
    - results/regression/parity_plot_ridge.png
    - results/regression/residuals_linear.png
    - results/regression/residuals_ridge.png
"""

from pathlib import Path
import json

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from src.utils import set_global_seed

from src.feature_engineering import (
    get_supervised_feature_lists,
    build_preprocessor,
)
from src.models import (
    split_train_test,
    train_linear_regression,
    evaluate_regression,
)

# Estilo dos gr√°ficos
sns.set(style="whitegrid", palette="muted")
plt.rcParams["figure.figsize"] = (8, 4)


def prepare_xy_for_regression(df: pd.DataFrame):
    """
    Prepara X e y para regress√£o cont√≠nua da review_score.

    - Remove linhas com review_score nulo
    - Usa as listas de features num√©ricas/categ√≥ricas definidas em get_supervised_feature_lists()
    """
    df = df.copy()
    df = df[~df["review_score"].isna()].copy()

    numeric_features, categorical_features = get_supervised_feature_lists()

    # Garantir que as colunas existem
    numeric_features = [c for c in numeric_features if c in df.columns]
    categorical_features = [c for c in categorical_features if c in df.columns]

    X = df[numeric_features + categorical_features]
    y = df["review_score"].astype(float)

    return X, y, numeric_features, categorical_features


def parity_plot(y_true, y_pred, title: str, out_path: Path):
    """
    Plota gr√°fico de paridade (y_true vs y_pred) e salva em arquivo.
    """
    # Limitar visualiza√ß√£o ao intervalo v√°lido (1 a 5)
    y_true_plot = y_true.clip(1, 5)
    y_pred_plot = np.clip(y_pred, 1, 5)

    plt.figure(figsize=(8, 4))
    sns.scatterplot(x=y_true_plot, y=y_pred_plot, alpha=0.3)
    min_val, max_val = 1, 5
    plt.plot([min_val, max_val], [min_val, max_val], linestyle="--")
    plt.xlabel("Valor real (review_score)")
    plt.ylabel("Valor previsto")
    plt.title(title)
    plt.xlim(min_val, max_val)
    plt.ylim(min_val, max_val)
    plt.xticks([1, 2, 3, 4, 5])
    plt.yticks([1, 2, 3, 4, 5])
    plt.tight_layout()
    out_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(out_path, dpi=120)
    plt.close()
    print(f"Gr√°fico de paridade salvo em: {out_path.resolve()}")


def residuals_plot(y_true, y_pred, title: str, out_path: Path):
    """
    Plota gr√°fico de res√≠duos (y_true vs erro) e salva em arquivo.
    """
    y_pred_plot = np.clip(y_pred, 1, 5)
    residuals = y_true - y_pred_plot
    plt.figure(figsize=(8, 4))
    sns.scatterplot(x=y_pred_plot, y=residuals, alpha=0.3)
    plt.axhline(0, color="red", linestyle="--")
    plt.xlim(1, 5)
    plt.xticks([1, 2, 3, 4, 5])
    plt.xlabel("Valor previsto (clamp 1-5)")
    plt.ylabel("Res√≠duo (y_true - y_pred)")
    plt.title(title)
    plt.tight_layout()
    out_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(out_path, dpi=120)
    plt.close()
    print(f"Gr√°fico de res√≠duos salvo em: {out_path.resolve()}")


def main() -> None:
    set_global_seed(42)
    DATA_FILE = Path("data/processed/olist_model_dataset.csv")
    RESULTS_DIR = Path("results/regression")

    if not DATA_FILE.exists():
        raise SystemExit(
            f"‚ùå ERRO: Arquivo de dados n√£o encontrado: {DATA_FILE.resolve()}.\n"
            f"Execute antes o 02_preprocessing.py."
        )

    print("üìÑ Lendo base de modelagem em:", DATA_FILE.resolve())
    df = pd.read_csv(DATA_FILE)

    # ============================================================
    # 1) Preparar X, y para regress√£o
    # ============================================================
    print("\nüìå Preparando features e target (review_score cont√≠nuo)...")
    X, y, numeric_features, categorical_features = prepare_xy_for_regression(df)

    print(f"Formato X: {X.shape}")
    print(f"Formato y: {y.shape}")
    print("Estat√≠sticas de review_score:")
    print(y.describe())

    # Preprocessador (StandardScaler + OneHotEncoder)
    preprocessor = build_preprocessor(numeric_features, categorical_features)

    # Divis√£o treino/teste (sem estratificar, porque √© regress√£o)
    tt = split_train_test(X, y, test_size=0.2, random_state=42, stratify=False)
    print("\nDivis√£o treino/teste realizada.")
    print(f"Treino: {tt.X_train.shape[0]} linhas")
    print(f"Teste : {tt.X_test.shape[0]} linhas")

    # ============================================================
    # 2) Treinar modelos de regress√£o
    # ============================================================
    print("\nüöÄ Treinando modelos de regress√£o...")

    print("\n‚û° Treinando Regress√£o Linear...")
    linear_model = train_linear_regression(
        preprocessor, tt.X_train, tt.y_train, ridge=False
    )

    print("\n‚û° Treinando Regress√£o Ridge (alpha = 1.0)...")
    ridge_model = train_linear_regression(
        preprocessor, tt.X_train, tt.y_train, ridge=True, alpha=1.0
    )

    # ============================================================
    # 3) Avaliar modelos
    # ============================================================
    print("\nüìä Avaliando modelos...")

    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    results = {}

    # Linear
    metrics_linear = evaluate_regression(linear_model, tt.X_test, tt.y_test)
    print("\n=== Regress√£o Linear ===")
    print(f"RMSE: {metrics_linear['rmse']:.4f}")
    print(f"R¬≤  : {metrics_linear['r2']:.4f}")
    results["linear_regression"] = metrics_linear

    # Ridge
    metrics_ridge = evaluate_regression(ridge_model, tt.X_test, tt.y_test)
    print("\n=== Regress√£o Ridge ===")
    print(f"RMSE: {metrics_ridge['rmse']:.4f}")
    print(f"R¬≤  : {metrics_ridge['r2']:.4f}")
    results["ridge_regression"] = metrics_ridge

    # ============================================================
    # 4) Gr√°ficos (paridade e res√≠duos)
    # ============================================================
    print("\nüìà Gerando gr√°ficos de paridade e res√≠duos...")

    # Para pegar y_pred, vamos reaproveitar evaluate_regression de forma simples:
    # como j√° temos os modelos treinados, chamamos .predict diretamente.
    y_pred_linear = linear_model.predict(tt.X_test)
    y_pred_ridge = ridge_model.predict(tt.X_test)

    parity_plot(
        tt.y_test,
        y_pred_linear,
        title="Regress√£o Linear - Paridade (review_score)",
        out_path=RESULTS_DIR / "parity_plot_linear.png",
    )
    parity_plot(
        tt.y_test,
        y_pred_ridge,
        title="Regress√£o Ridge - Paridade (review_score)",
        out_path=RESULTS_DIR / "parity_plot_ridge.png",
    )

    residuals_plot(
        tt.y_test,
        y_pred_linear,
        title="Regress√£o Linear - Res√≠duos",
        out_path=RESULTS_DIR / "residuals_linear.png",
    )
    residuals_plot(
        tt.y_test,
        y_pred_ridge,
        title="Regress√£o Ridge - Res√≠duos",
        out_path=RESULTS_DIR / "residuals_ridge.png",
    )

    # ============================================================
    # 5) Salvar m√©tricas em JSON
    # ============================================================
    results_file = RESULTS_DIR / "regression_results.json"
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print("\nüíæ Resultados de regress√£o salvos em:", results_file.resolve())
    print("\n‚úÖ Regress√£o da review_score conclu√≠da com sucesso.")


if __name__ == "__main__":
    main()
